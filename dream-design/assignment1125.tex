\documentclass{article}

% The geometry package allows for easy page formatting.
\usepackage{geometry}
\geometry{letterpaper}

% Load up special logo commands.
\usepackage{doc}

% Package for formatting URLs.
\usepackage{url}

% Packages and definitions for graphics files.
\usepackage{graphicx}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
%
% Set the title, author, and date.
%
\title{Usability of Security Measures in Ubiquitous Computing Environments}
\author{Joaquin Loustau}
\date{October 16, 2014}

%
% The document proper.
%
\begin{document}

% Add the title section.
\maketitle

% Add an abstract.
\abstract{
1. A description of the type of system for which you have created the design, focusing on any particularly usability issues that you'd like to address.
2. A top-level design or layout
3. At least two usage scenarios
4. Rationale for your design: relevant priorities, mental properties, interaction design concepts, guidelines, principles, theories, etc. 
5. Usability metric "forecast" analysis of your design --if implemented then tested, what would be your design's strong metrics? Weak metrics? Explain your choices. 
Illustrate things as needed, with diagrams 
}

% Add various lists on new pages.
\pagebreak
\tableofcontents

% Start the paper on a new page.
\pagebreak

%
% Body text.
%
\section{Introduction}
\label{introduction}
Smartwatches promise to bring enhanced convenience to
common communication, creation and information retrieval
tasks. Due to their prominent placement on the wrist, they
must be small and otherwise unobtrusive, which limits the
sophistication of interactions we can perform. This problem
is particularly acute if the smartwatch relies on a
touchscreen for input, as the display is small and our fingers
are relatively large. In this work, we propose a complementary
input approach: using the watch face as a multi-degreeof-freedom,
mechanical interface. We developed a proof of
concept smartwatch that supports continuous 2D panning
and twist, as well as binary tilt and click. To illustrate the
potential of our approach, we developed a series of example
applications, many of which are cumbersome – or even impossible
– on today’s smartwatch devices.

The wristwatch has been an ever-present wearable technology
since its inception in the early 1900s, and has undergone
continuous technical refinement since that time. Researchers
have long viewed the immediacy and ubiquity of
the wristwatch as a vehicle for computation, pushing its capabilities
to ever-greater heights. In 2000, IBM demonstrated
the first watch running a full operating system [20].
However, unlike smartphones, which can be scaled to a variety
of sizes, smartwatches must be small and unobtrusive
in order to remain socially acceptable, which has long limited
their practicality.

Recently, smartwatches have experienced a resurgence of
interest as electronics have become more powerful and
power efficient, making them more practical and capable
than ever before. Products like the Pebble smartwatch have
been popularized in the public press, and prominent manufacturers
such as Qualcomm, Sony, Motorola and Samsung.

n-air gestures can utilize area around the watch for input
with minimal screen occlusion. For example, the Gesture
Watch [8] and HoverFlow [9] used IR proximity sensors to
capture gestures performed above a device. Ni and Baudisch
[15] used a tiny, wrist-worn, high-resolution optical
sensor to recognize gestures performed on top of it. Abracadabra
[4] used free-space magnetic tracking to sense an instrumented
finger near a wrist-worn device. However, these
gesture-based techniques require specific clutching mechanisms,
lack tactile feedback, and are generally indiscreet.
Our approach hopes to mitigate these issues by providing
users a physical, direct manipulation interface.

The approach we present complements contemporary smartwatch
input mechanisms, namely touch, physical buttons
and voice. Our approach does not hinder any of latter modalities,
while simultaneously enabling new dimensions of
input, which we view as a significant benefit. That being
said, there are several drawbacks and limitations that should
also be noted, which we now describe.

As with capacitive touch, buttons and voice, there is a danger
of accidental input. This might occur by snagging on
clothing or being “pushed” when e.g., the hands are resting
on a table. Like other modalities, an “unlock” mechanism
might have to be employed to reduce false activations. Indeed,
a device could have one such mechanism shared by
all input modalities. 

In this work, we designed and implemented a new smartwatch
interaction modality that uses the watch face as a
multi-degree-of-freedom mechanical interface, enabling users
to pan, zoom, navigate, select and perform other actions
using simple physical controls. We demonstrated these capabilities
with a suite of example applications, built around
five interaction techniques. Our approach is inexpensive,
potentially compact, and can complement existing inputs,
such as physical buttons, touch and voice.

The popularity of smartwatches has increased rapidly in
the last year. Smartwatches are being hailed as a new
disruptive technology that might bring wearable
computing to the masses. As smart watches are
normally worn on the wrist, we see a big potential for
them to digitally augmented gestures performed in
day-to-day contexts. 

In this paper, we describe the
design and development of an application for a
smartwatch to assist office employees in easily locking
and unlocking doors, in acquiring room information and
notifying others when they want to enter their office. 

 Because of the
small screen we wanted to make the interaction fast.
We decided to implement three types of physical
gestures to support the most important functionalities.
First, we provide the opportunity to perform a virtual
knock with the same gesture as a real knock. Secondly,
we support opening/closing doors using the gesture of
turning your wrist, just like turning a key to open a
door. Finally, the last gesture we provide is swiping
your arm to bring you back to the home screen with
room scanning functionality.

Knowledge workers tend to drop by each other’s offices
regularly, for example, to ask for assistance or quickly
discuss something. Even with the door open, knocking
on the door is a common gesture to politely indicate
your presence and check whether you are not
interrupting the person. Using smartwatches, we could
digitally augment these gestures, which can provide a
number of benefits. For example, when a person is not
in his office, knock gestures could still be recognized
and transferred to that person’s smartwatch. This
allows office workers to keep a record of who came by
and who they might have missed. Additionally, it is
often annoying to interrupt a phone or Skype call to tell
the person knocking on the door that now is not a good
time. Depending on who is knocking on the door, it
might be important enough to interrupt the phone call.
Using our smartwatch applications, the person in the
call gets a notification about the virtual knock, and can
choose to deny their colleague access or let them in,
without having to interrupt the call. 

Keys (or keycards) are commonly used to open doors in
office buildings. However, they also have several
disadvantages: generic keys could still provide access
to restricted rooms; they might be lost or forgotten
(e.g. people could lock themselves out); or people
might forget to lock the door, which could lead to theft
of personal belongings or sensitive information. Our
Office Smartwatch application tracks the identity of its
users to provide more fine-grained access control.
Using the user’s identity, we can restrict access only to
the doors that they are allowed to open. Users do not
have to remember to bring their keys, assuming they
always have their smartwatch on their wrist. To prevent
theft, doors could be automatically locked after a
specific period of time and door entry and exit could be
logged.

In our application, we have three kinds of feedback:
visual feedback on the smartwatch display, audio
feedback (e.g., a knocking sound when performing a
virtual knock) and vibration in case of a notification.
Also for smartwatches, visual feedback remains the
most common way of providing feedback to users. In
order to keep the display contents easy to grasp, we
only show information that is essential, following the
recommendations of Kärkkäinen and Laarni [8]

 However, when the user looked
at the screen, he only got feedback of the last gesture
that was performed. To address this problem, we
decided to add audio feedback and play a sound every
time a gesture has been detected. Users should be able
to immediately distinguish the performed gesture based
on the sound they hear. For example, when a virtual
knock gesture is performed, the device plays a real
knocking sound. For the opening/closing gesture we
decided to use a rattling keys sound. For going back to
the scan functionality, we use a sibilant whoosh sound

 Vibrations are only used
sparingly, as they can be annoying to the user.
Vibrations are only used for notifications: for notifying
the user when someone is knocking on their door, when
they need to attend a meeting, in case of an error, or
when the user tries to perform an action without the
right permissions (e.g. opening the boss’s office door). 

Smartwatches now provide users with access to many
applications on smartphones direct from their wrists,
without the need to touch their smartphone. While
applications such as email, messaging, calendar and
social networking provide views on the watch, there is
normally no text entry method so users cannot reply on
the same device. Here we introduce requirements for
smartwatch text entry, an optimised alphabetic layout
and present a prototype implementation together with
preliminary user feedback. While raising some problems,
the feedback gives indicates that reasonable quality and
speed is achievable on a smartwatch and encourages our
future work.

Before the widespread adoption of touch screen
smartphones, 12-key physical keypad phones were the
most common text entry method on small devices
(sometimes much smaller than the current relatively
large screen phones). Predictive technologies (e.g. [4,
10, 11]) interpreted the ambiguous keys (usually three
or four letters per key) into words. This approach was
shown to achieve around 10 words per minute (wpm) for
novices and around 20-25 wpm for experts in controlled
studies [12]. We investigated using this approach with
reduced number of keys - initially targeting watches [3],
but due to technological restrictions our system was
implemented on a touchscreen handheld, and later, to
reduce movement, on physical key phones [6]. While in
theory ambiguous predictive text quality was very high
(over 90% accurate), each key sequence could match
many different words. Some of these sequences included
pairs of common words that caused particular problems
(e.g. on a standard phone keypad he and if were typed
on the same keys, as were good and home). The early
models of prediction were based on simple unigram
dictionary models where the most common word
matching a sequence was suggested. Nowadays, phones
have much more power and memory so can easily
support more complex prediction models, which greatly
reduces the impact of ambiguity by taking the context of
the words into account.

One system of particular note is ZoomBoard [17] that
miniaturises the QWERTY keyboard onto a watch, with
the user first zooming into an area then picking a letter.
ZoomBoard achieved approx. 10wpm in studies and our
work is essentially investigating whether predictive
based approaches can surpass this using single taps per
letter. Many domestic appliances such as TV guides and
games consoles use a date-stamp inspired method,
where the user scrolls through the alphabet and picks
letters on a 2D line or 3D grid. In their early work on
small device text entry Bellman and MacKenzie [1]
showed this to be a slow entry method that was not
particularly helped by dynamic optimisation. 

Speech input is an obvious alternative but is still prone
to problems with background noise, spoken accents and
is less private and discrete than typing.  

Interaction was defined as follows:

1. A tap on an ambiguous key enters that key number and updates the current word display to reflect the most likely word from the disambiguation engine based on the current number-key sequence. 

2. A first tap on the cental zone adds a space, with subsequent taps rotating round alternative suggestions that match the ambiguous entry. 

3. Swipes are defined as shown in table 1. In punctuation and numeric modes the zones 1...6 are replaced with alternative layouts. Where available, a rightwards swipe gesture can be used for word completion. 

4. A long press on the centre zone enters edit mode to allow movement of the caret while a long press on the alphabetic keys will show extended characters for that key (e.g. )

As documented by Everett Rodgers in The Diffusion of Innovations, no fundamentally new product type succeeds solely based on the fact that it’s attractive; it succeeds because it does something genuinely useful at a price point low enough that people don’t consider it a luxury. And then it becomes normal and even attractive because it was first useful.

There are 3 major functions of Wear: a Google Now-style "homescreen" with a scrollable list of cards, a rich-notification system that alerts you to information from your smartphone, and a series of contextual tools that pop up during certain activities (Call, Hangouts). All of these functions flow together when necessary, and they depend on a smartphone, if only for the data connection in some cases.

These will look a lot like the cards in the Context Stream: short snippets of relevant information, with an optional photo backdrop. Again, you'll be able to swipe to the right to see expanded information. An action button will let you perform commands on your phone without actually touching it, usually via voice, though the full capability of these actions hasn't been revealed yet.
 
Previously I have written about smartwatches and how I was unsure as to their use. I think that currently we are asking too much from them. At it’s very core, a watch is there to provide you with the time. We have many variations of watches, some offer more, quite a few can tell you the date or the day of the week, or even the current altitude.

When outside of a 10m radius of your attached phone, the watch will alert you to an incoming call, if you are unable to return to your phone to answer the call you will have an option to send a message to the caller informing them you will return their call soon.

Damn my infernal pants pockets. The salesperson at the store said they would be useful for storing small personal items—car keys, loose change, lint—but he didn’t warn me that they’d be a crappy place to keep my smartphone. Somehow, some way, whenever I need my phone the most, it’s lodged deep in my front pocket, entrenched and inaccessible.

Sound familiar? Indeed. So a smartwatch such as the Samsung Galaxy Gear would seem to solve a lot of problems. In theory, it puts a bunch of critical smartphone functions on your wrist, saving you the trouble of extricating your phone from your pocket to make a phone call, snap a photo, or run a few apps.

It’s worth noting that when a smartwatch runs out of juice, you don’t lose just the smart functions. The display dies, and you lose the ability to even tell time. At this point, you really need to appreciate the shiny brushed metal, because you’re wearing nothing more than an expensive bracelet.

When one of your contacts calls your phone (well, your giant Galaxy Note 3 phablet), a notification appears on the Gear, showing the face and name of the person calling. You can accept the call with a swipe gesture, and then begin talking directly into the watch.

Multitasking

Smartwatch and NFC 

 Even today, mobility is for most of us still very much connected with the concept of the smart phone. But mobility has grown to much more than this single class of devices – it is indeed the birthplace for a many new device categories. The most visible of these others categories so far are tablets, the second generation of mobile devices. But this is only the beginning. Smart watches and smart glasses are lurking around the corner, and are already emerging. We will enter the era of wearable computing – the third generation of mobile devices which will be closer to us and more personal than any other device before.

I'm so tired of smart phones destroying the social function of eating a meal with others. Kids of all ages zone others out by pulling out their smartphones in both public and private places, as if telling everyone they are around that THEIR tiny little world is the most important by far. If the Apple Watch helps eliminate some of that hardware at the table, great. Maybe a small watch will keep the online engagement to smaller bites and less intrusive manners. If so, bring them on. If it makes everyone even more isolated and neglectful of the world around them, God help us.

Even today it’s apparent that these new classes of mobile devices do not replace the older ones, but rather complete them. Smart phones did not go extinct after the arrival of tablets, but tablets are superior to smart phones for functions like reading e-books or watching movies. It often depends on the context if a tablet or a smart phone is the better tool of choice. A ten inch tablet is mainly a couch device, while a smart phone can still be used for reading when being out of home. The trend is moving towards a multitude of mobile devices, each with a distinctive usage profile and all connected with each other. There is no single mobile device anymore – the personal mobile device ecosystem is the more powerful Swiss Army knife. 

Smart watches will have sensors and be close to our body to constantly measure our pulse and other body functions. The quantified self movement will gain further traction.

There will also be a major challenge for the class of wearable computing devices. That is the user interface. An adequate smart phone user interface was missing for a long time. An adequate UI was the major success factor of the iPhone, the reason it was superior to all other approaches at that time. The same challenge is ahead for the new class of devices. Touch screens are not adequate anymore for devices much smaller than a smart phone. One approach, followed by Google, is voice recognition. It still needs to be proved that this works well in practice, but it seems to be the proper approach for devices close to your mouth or face. For smart watches this differs. Probably only James Bond aficionados are going to start talking to their watch. Indeed, another kind of user interface is a better choice for devices at your wrist – a technology which emulates the most intuitive movements we do with our hands and arms – touching and pointing to something. This technology is NFC.

NFC, or Near-Field-Communication is a radio technology similar to RFID or Bluetooth, with the distinct feature that it requires close contact for transmission of data. At first glance a disadvantage, this brings the real power to NFC. Data transmitted is context-sensitive, by a “touch” on the target. This target can either be another NFC capable device or a so-called tag, a small, flat chip that contains a piece of data. When such a tag is touched with a NFC capable device the data can be read, and even a distinct action can be initiated. A smart poster containing NFC tags can have several touch points, one for showing the location of the next cinema theatres, another for playing a trailer video, and a third for purchasing tickets. Or a cafe could have a tag at its entry door for connecting with its Wifi (including transmitting a password for temporary access in the network) and downloading a coupon.

With NFC, a new type of user interface appears. It is not on the screen anymore, but deeply embedded in the real world. For smartphones, such technology was so far of limited success because it is convenient to control with the touchscreen. But for devices like a smart watch there will not be a screen of adequate size. Touching a NFC tag which initiates a context-dependent action is the easier thing to do, especially because the smart watch is on your wrist, and pointing to or touching something is one of the most intuitive human gestures, understood by everybody. With NFC and smart watches, this gesture has the potential to connect the real and the virtual world in a new and innovative way.

In office spaces, knowledge workers interact both with
each other and with various analog and digital devices
in the office. We think that the office environment
opens up an interesting space to utilize smartwatches
to support and digitally augment interactions.

gyroscope

 As smart watches are
normally worn on the wrist, we see a big potential for
them to digitally augmented gestures performed in
day-to-day contexts.

While the office environment offers a rich set of
different interactions between humans and also
between humans and various digital devices, we started
our development of the Office Smartwatch by focusing
on a specific use case. We explored various ways to
support interactions usually performed when entering a
room or getting information about specific office room.
In various brainstorming sessions, we derived the
following set of interactions to digitally augment
commonly used gestures (see Figure 1). Because of the
small screen we wanted to make the interaction fast.
We decided to implement three types of physical
gestures to support the most important functionalities.
First, we provide the opportunity to perform a virtual
knock with the same gesture as a real knock. Secondly,
we support opening/closing doors using the gesture of
turning your wrist, just like turning a key to open a
door. Finally, the last gesture we provide is swiping
your arm to bring you back to the home screen with
room scanning functionality.
Knowledge workers tend to drop by each other’s offices
regularly, for example, to ask for assistance or quickly
discuss something. Even with the door open, knocking
on the door is a common gesture to politely indicate
your presence and check whether you are not
interrupting the person. Using smartwatches, we could
digitally augment these gestures, which can provide a
number of benefits. For example, when a person is not
in his office, knock gestures could still be recognized
and transferred to that person’s smartwatch. This
allows office workers to keep a record of who came by
and who they might have missed. Additionally, it is
often annoying to interrupt a phone or Skype call to tell
the person knocking on the door that now is not a good
time. Depending on who is knocking on the door, it
might be important enough to interrupt the phone call.
Using our smartwatch applications, the person in the
call gets a notification about the virtual knock, and can
choose to deny their colleague access or let them in,
without having to interrupt the call. 

Keys (or keycards) are commonly used to open doors in
office buildings. However, they also have several
disadvantages: generic keys could still provide access
to restricted rooms; they might be lost or forgotten
(e.g. people could lock themselves out); or people
might forget to lock the door, which could lead to theft
of personal belongings or sensitive information. Our
Office Smartwatch application tracks the identity of its
users to provide more fine-grained access control.
Using the user’s identity, we can restrict access only to
the doors that they are allowed to open. Users do not
have to remember to bring their keys, assuming they
always have their smartwatch on their wrist. To prevent
theft, doors could be automatically locked after a
specific period of time and door entry and exit could be
logged. 

When doing gestures, it is difficult to see what is
happening on the screen. During the development of
our app, we noticed that when a gesture was
performed, the device could have detected two different
gestures in sequence. However, when the user looked
at the screen, he only got feedback of the last gesture
that was performed. To address this problem, we
decided to add audio feedback and play a sound every
time a gesture has been detected. Users should be able
to immediately distinguish the performed gesture based
on the sound they hear. For example, when a virtual
knock gesture is performed, the device plays a real
knocking sound. For the opening/closing gesture we
decided to use a rattling keys sound. For going back to
the scan functionality, we use a sibilant whoosh sound.
Audio feedback will also be generated when someone
needs to be notified, like receiving a virtual knock on
his device. This is helpful because users might not look
on their watch at all times. Vibrations are only used
sparingly, as they can be annoying to the user.
Vibrations are only used for notifications: for notifying
the user when someone is knocking on their door, when
they need to attend a meeting, in case of an error, or
when the user tries to perform an action without the
right permissions (e.g. opening the boss’s office door). 

Home Appliances 
As a handy side-benefit, that circular case (i.e. pocketwatches and wristwatches) also has fewer hard, pointy edges to tear and poke at our skin and pockets.

The elegance of maintaining a classic, circular face was a non-negotiable for them. 

To operate, the Apple Watch needs to be paired with an iPhone, so they’ve decided to willingly break UI continuity between these two closely cooperating devices. In other words, the Facebook icon on the phone and on the watch will always be different in a very fundamental way.

The fashion-will-fix-smartwatches narrative is a really compelling story. It’s also completely wrong — or, at minimum, flies in the face of decades of study about how new technologies get adopted. As documented by Everett Rodgers in The Diffusion of Innovations, no fundamentally new product type succeeds solely based on the fact that it’s attractive; it succeeds because it does something genuinely useful at a price point low enough that people don’t consider it a luxury. And then it becomes normal and even attractive because it was first useful.

So if it’s not fashion, what is standing between today and the smartwatches-everywhere future? One thing: a great, unique interface that showcases how much better this new product type can perform both new and existing functions.

Unfortunately, neither the watch-emulating button interface of the Pebble nor the touchscreen-on-a-strap concepts from Google and Samsung hit the mark. They simply feel like a previous generation of interface slapped onto an emerging form — which is exactly what they are.

After careful consideration of existing solutions, emerging and available technology, and the form factor’s constraints, I have identified four principles for designing good smartwatch interfaces. Using these principles, I’ll evaluate the viability of three feature candidates to make smartwatches intuitive: voice, gesture, and contextual response.

First, the 4 Principles of Good Wearable Design
1. Glances, not stares: No smartwatch should ever command the attention, especially the eyesight, of a user for more than a few seconds at a time. Spending longer erodes any advantage over a smartphone
2. Interact once, display many times: Smartwatches should primarily provide displays of information and prompts for action rather than providing rich interactive elements, meaning they will show lots of information that is passively consumed.
3. Speed over accuracy: Consumer smartwatches should be flexible, fun, in-the-moment companions, which means they should make lots of ignorable suggestions rather than waiting to make a few suggestions that it deems perfectly right, as current predictive services do.
4. Pass the hallucination test: Smartwatch use can be perceived as novel behavior, but it can’t present like Bluetooth headsets, which make it impossible to know who is on the phone and who is screaming at an imaginary friend on the street.

Ever since Apple launched Siri, it’s been expected that voice control would become the next big thing. Since smartwatches don’t have room for even virtual keyboards, many have suggested that voice could make for an ideal mode of interaction.

In practice, it’s a dead-end. Voice is highly imprecise, as its reliability depends on being in a quiet place (which rules out virtually any public use case, defeating the point of a wearable). This means users need to carefully monitor and repeat commands to get what they want, which fails my first three principles of good design. Moreover, it fails the hallucination test horribly.

Here’s why: One irony of today’s touchscreen- or button-based smartwatches is that they can’t be operated by the hand closest to them. Shakes, slaps, twists, arm flips, brushes, and other gestures could all make great methods for dismissing notifications, skipping messages or music tracks, and communicating with a simple yes/no–and either arm could get involved. It could be argued that fitness bands–to date the most successful category of wearables–are controlled by gesture, as they use motion sensors to detect activity. Gesture control speaks to the first three principles: It’s a glance-and-interact model focused around the speedy display of information that may be useful. And provided these gestures skew subtle, they would have no issue passing the hallucination test.

If contextual response is to be more than a roulette wheel of data analytics, however, it will require far more–and more accurate–data than we currently have, not to mention consumer control of it. As a result, contextual response UIs will likely be secondary to gesture at first, though they would improve and become more prominent over time.


\bibliography{assignment1016}
\bibliographystyle{plain}

\end{document}
